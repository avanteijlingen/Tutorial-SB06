{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714c7f8c",
   "metadata": {},
   "source": [
    "# Now we are going to test and implement more advanced machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, pandas, warnings\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "Seed = 72993\n",
    "np.random.seed(Seed)\n",
    "nJobs = 2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddd8526",
   "metadata": {},
   "source": [
    "# Load our data similar to before\n",
    "## This time we will do cross-validation on the training set so we will only need training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pandas.read_csv(\"Dipeptides_Judred.csv\", index_col=0)\n",
    "#print(parameters)\n",
    "targets = pandas.read_csv(\"APs.csv\", index_col = 0)\n",
    "#print(targets)\n",
    "\n",
    "Forcefield = \"2.1\"\n",
    "targets = targets[targets[\"FF\"] == Forcefield]\n",
    "targets.index = targets[\"pep\"]\n",
    "\n",
    "targets = targets[\"mean\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(parameters, targets, test_size=0.33, random_state=9876, shuffle=True)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state=9876, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9603a2a",
   "metadata": {},
   "source": [
    "#### We will now perform hyperparameter optimization for several models and rank them against each other. Due to limit time we are keeping the number of combinations of hyperparameters relatively small but you can play around with it to make further improvements.\n",
    "\n",
    "Due to the way Jupyter notebooks works, dont move onto the next block of code after running a hyperparameter optimization until you see the console print: \"Best params from grid search: ....\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db72b8",
   "metadata": {},
   "source": [
    "# SVM rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4fd381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters we want to test\n",
    "SVRrbf_param_grid = {\n",
    "        \"kernel\": [\"rbf\"],\n",
    "        \"gamma\": [\"scale\", \"auto\"],\n",
    "        \"C\": [0.1, 1, 10, 100], \n",
    "        \"epsilon\": np.linspace(0.1, 1, 10), \n",
    "        \"max_iter\": [-1],\n",
    "        \"tol\": [0.01, 0.001, 0.0001], \n",
    "        \"verbose\":[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd039a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR()\n",
    "HPO_model = GridSearchCV(estimator = model, param_grid = SVRrbf_param_grid, cv = 5, n_jobs = nJobs, verbose = True)\n",
    "HPO_model.fit(X_train.values, y_train.values.reshape(-1))\n",
    "print(\"\\nBest params from grid search:\")\n",
    "print(HPO_model.best_params_)\n",
    "SVMrbf_hyperparameters = HPO_model.best_params_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd45649",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_param_grid = {'bootstrap': [True, False],\n",
    "                  'criterion': ['squared_error', 'absolute_error'],\n",
    "                  'max_depth': [None],\n",
    "                  'max_features': [\"sqrt\", \"log2\", None],\n",
    "                  'max_leaf_nodes': [None],\n",
    "                  'min_impurity_decrease': [0.0],\n",
    "                  'min_samples_leaf': [1, 2],\n",
    "                  'min_samples_split': [0.5, 1.0],\n",
    "                  'min_weight_fraction_leaf': [0.0, 0.01, 0.1],\n",
    "                  'n_estimators': [10, 100],\n",
    "                  'n_jobs': [nJobs],\n",
    "                  'oob_score': [False],\n",
    "                  'verbose': [False],\n",
    "                  'warm_start': [False, True],\n",
    "                  \"random_state\":[Seed]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "HPO_model = GridSearchCV(estimator=model, param_grid=RF_param_grid, cv = 5, n_jobs = nJobs, verbose = True)\n",
    "HPO_model.fit(X_train.values, y_train.values.reshape(-1))\n",
    "print(\"\\nBest params from grid search:\")\n",
    "print(HPO_model.best_params_)\n",
    "RF_hyperparameters = HPO_model.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce6a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RF_hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8710d5",
   "metadata": {},
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ffe8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_param_grid = {\n",
    "        \"activation\": [\"relu\"],\n",
    "        \"alpha\":[0.0001, 0.1],\n",
    "        \"batch_size\": [20],\n",
    "        \"early_stopping\":[True],\n",
    "        #epsilon\n",
    "        \"hidden_layer_sizes\": [(10,), (10,2), (10,3)] + [(100,), (100,2), (100,3)],\n",
    "        \"learning_rate\":[\"adaptive\"],\n",
    "        \"learning_rate_init\": [0.001],\n",
    "        \"max_iter\":[100, 1000],\n",
    "        #momentum\n",
    "        #\"power_t\":[0.25, 0.5, 0.75], \n",
    "        \"random_state\":[Seed], \n",
    "        \"shuffle\":[False], \n",
    "        \"solver\": [\"sgd\", \"adam\"],\n",
    "        \"tol\": [0.01, 0.1], \n",
    "        \"validation_fraction\":[0.1],\n",
    "        \"n_iter_no_change\": [5, 10],\n",
    "        \"verbose\":[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor()\n",
    "HPO_model = GridSearchCV(estimator = model, param_grid = MLP_param_grid, cv = 5, n_jobs = nJobs, verbose = True)\n",
    "HPO_model.fit(X_train.values, y_train.values.reshape(-1))\n",
    "\n",
    "print(\"\\nBest params from grid search:\")\n",
    "print(HPO_model.best_params_)\n",
    "MLP_hyperparameters = HPO_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3327f86a",
   "metadata": {},
   "source": [
    "# Test and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMmodel = SVR(**SVMrbf_hyperparameters)\n",
    "RFmodel = RandomForestRegressor(**RF_hyperparameters)\n",
    "DNNmodel = MLPRegressor(**MLP_hyperparameters)\n",
    "\n",
    "SVMmodel.fit(X_train, y_train)\n",
    "RFmodel.fit(X_train, y_train)\n",
    "DNNmodel.fit(X_train, y_train)\n",
    "\n",
    "SVM_predictions = SVMmodel.predict(X_val)\n",
    "RF_predictions = RFmodel.predict(X_val)\n",
    "DNN_predictions = DNNmodel.predict(X_val)\n",
    "\n",
    "SVM_rmse = mean_squared_error(y_val, SVM_predictions, squared=False)\n",
    "RF_rmse = mean_squared_error(y_val, RF_predictions, squared=False)\n",
    "DNN_rmse = mean_squared_error(y_val, DNN_predictions, squared=False)\n",
    "\n",
    "print(\"Support vector machine RMSE:\", SVM_rmse)\n",
    "print(\"Random forest RMSE:\", RF_rmse)\n",
    "print(\"Deep neural network RMSE:\", DNN_rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1606862e",
   "metadata": {},
   "source": [
    "# Visualize the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1553d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(SVM_predictions, y_val, label=\"SVM\")\n",
    "plt.scatter(RF_predictions, y_val, label=\"RF\")\n",
    "plt.scatter(DNN_predictions, y_val, label=\"DNN\")\n",
    "\n",
    "plt.plot([1,2.7], [1,2.7], lw=1, c=\"black\")\n",
    "plt.xlabel(\"Predicted AP\")\n",
    "plt.ylabel(\"True AP\")\n",
    "plt.gcf().set_dpi(100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a807136f",
   "metadata": {},
   "source": [
    "# Re-weighting\n",
    "## Since we have an unbalanced dataset we may wish to give more weight to those with high AP (few) over those with a low AP (many) - especially since these are the more interesting ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMmodel.fit(X_train, y_train, sample_weight = y_train-0.5)\n",
    "RFmodel.fit(X_train, y_train, sample_weight = y_train-0.5)\n",
    "\n",
    "\n",
    "SVM_predictions = SVMmodel.predict(X_val)\n",
    "RF_predictions = RFmodel.predict(X_val)\n",
    "\n",
    "\n",
    "SVM_rmse = mean_squared_error(y_val, SVM_predictions, squared=False)\n",
    "RF_rmse = mean_squared_error(y_val, RF_predictions, squared=False)\n",
    "\n",
    "\n",
    "print(\"Support vector machine RMSE:\", SVM_rmse)\n",
    "print(\"Random forest RMSE:\", RF_rmse)\n",
    "\n",
    "plt.scatter(SVM_predictions, y_val, label=\"SVM\")\n",
    "plt.scatter(RF_predictions, y_val, label=\"RF\")\n",
    "\n",
    "plt.plot([1,2.7], [1,2.7], lw=1, c=\"black\")\n",
    "plt.xlabel(\"Predicted AP\")\n",
    "plt.ylabel(\"True AP\")\n",
    "plt.gcf().set_dpi(100)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf34247",
   "metadata": {},
   "source": [
    "# Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df2cc3",
   "metadata": {},
   "source": [
    "## 1 implement and optimize a different machine learning model, such as the [Extra Trees Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92f3386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c659fd45",
   "metadata": {},
   "source": [
    "## 2 Add an additional parameters to the dataset to see if it can contribute to better AP predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters[\"new parameter\"] = function(peptide)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
